{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - MapReduce\n",
    "\n",
    "In this lab, we are practicing the MapReduce programming paradigm. \n",
    "\n",
    "We will complete the tasks using the accompanied *mapreduce* package (as **mapreduce.py**) and MRJob. Please download the **mapreduce.py** file from our online class resource page, and place it in the same folder with your notebook.\n",
    "\n",
    "Please also install MRJob through **pip install mrjob**.\n",
    "\n",
    "For each invocation of an MapREduce job (with mr.run()), you are expected to supply a mapper, a reducer and/or a combiner as needed. Below are sample usage of the package:\n",
    "\n",
    "```python\n",
    "    # Run on input1 using your mapper1 and reducer1 function\n",
    "    output = list(mr.run(input1, mapper1, reducer1))\n",
    "\n",
    "    # Run on input2 using only your mapper2, no reduce phase\n",
    "    output = list(mr.run(enumerate(input2), mapper2, combiner2))\n",
    "    \n",
    "    # Run on input3 using 2 nested MapReduce jobs\n",
    "    output = mr.run(mr.run(input3, mapper3, reducer3), mapper4)\n",
    "```\n",
    "    \n",
    "Please note that the input must be an iteratable of **key/value pairs**. If your inpu tdata does not have a key, you can simply add a null or index key through **enumerator(input)**. The output of the mr.run() is always a **generator**. You have to cast it to a list if you'd like to view, index or print it out.\n",
    "\n",
    "The tasks below also include those that are in Homework 2, but we're using MapReduce instead of Python's general Higher Order Functions.\n",
    "\n",
    "You will need **book.txt** and **citibike.csv** file from the class resource page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import mapreduce as mr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0\n",
    "\n",
    "Here is another concrete example on \"Word Count\" using the package. Assuming we have a text file named *book.txt*. Our task is to count the frequency of words in this document, and print the top 10. For illustration purposes, we use only the first 1000 lines of the book for counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 360),\n",
       " ('of', 326),\n",
       " ('and', 246),\n",
       " ('a', 169),\n",
       " ('or', 161),\n",
       " ('to', 101),\n",
       " ('with', 100),\n",
       " ('in', 88),\n",
       " ('on', 67),\n",
       " ('as', 56)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('book.txt', 'r',encoding='utf-8') as fi:\n",
    "    lines = [(i,line.strip()) for i,line in enumerate(fi) if i<1000]\n",
    "\n",
    "### After this, 'lines' stores a list of 1000 text lines\n",
    "def mapper(_, line):\n",
    "    for word in line.strip().split(' '):\n",
    "        if len(word)>0:\n",
    "            yield (word, 1)\n",
    "    \n",
    "def reducer(word, counts):\n",
    "    yield (word, sum(counts))\n",
    "\n",
    "wCounts = list(mr.run(lines, mapper, reducer))\n",
    "sortedCounts = sorted(wCounts, key=lambda x: -x[1])\n",
    "sortedCounts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Task 1 to Task 4, we re-do some tasks from Lab 3 (HOF) to familiarize ourselves with MapReduce\n",
    "\n",
    "## Task 1\n",
    "\n",
    "We would like to write a MapReduce job to count the total number of trips involved at each station. For example, if a trip starts at station A and stops at station B, the trip will count for both A and B. The output must be tuples, each consisting of a station name and a count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1 Ave & E 15 St', 795),\n",
       " ('1 Ave & E 44 St', 219),\n",
       " ('10 Ave & W 28 St', 422),\n",
       " ('11 Ave & W 27 St', 354),\n",
       " ('11 Ave & W 41 St', 461),\n",
       " ('11 Ave & W 59 St', 242),\n",
       " ('12 Ave & W 40 St', 217),\n",
       " ('2 Ave & E 31 St', 588),\n",
       " ('2 Ave & E 58 St', 125),\n",
       " ('3 Ave & Schermerhorn St', 34)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper1(_, row):\n",
    "    yield(row['start_station_name'],1)\n",
    "    yield(row['end_station_name'],1)\n",
    "    \n",
    "def reducer1(station, counts):\n",
    "    yield(station,sum(counts))\n",
    "   \n",
    "    \n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output1 = list(mr.run(reader, mapper1, reducer1))\n",
    "\n",
    "output1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2\n",
    "\n",
    "Below is an example of showing how to use nested jobs and jobs with mappers only using the mapreduce package, thus, no points are included. Our task here is that we would like to filter the output of Task 1 to display only those stations with more than 1000 trips involved, of course, using the MapReduce paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8 Ave & W 31 St', 1065),\n",
       " ('E 43 St & Vanderbilt Ave', 1003),\n",
       " ('Lafayette St & E 8 St', 1013),\n",
       " ('W 21 St & 6 Ave', 1057),\n",
       " ('W 41 St & 8 Ave', 1095)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper2(station, count):\n",
    "    if(count>1000):\n",
    "        yield(station,count)\n",
    "    \n",
    "\n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output2 = list(mr.run(mr.run(reader, mapper1, reducer1), mapper2))\n",
    "\n",
    "output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3\n",
    "\n",
    "We would like to count the number of trips taken between pairs of stations. Trips taken from station A to station B or  from station B to station A are both counted towards the station pair A and B. Please note that the station pair shoud be identified by station names, as a tuple, and in lexical order, i.e. (A,B) instead of (B,A) in this case. The output must be tuples, each consisting of the station pair identification and a count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['1 Ave & E 15 St', '1 Ave & E 15 St'], 5),\n",
       " (['1 Ave & E 15 St', '1 Ave & E 44 St'], 6),\n",
       " (['1 Ave & E 15 St', '11 Ave & W 27 St'], 1),\n",
       " (['1 Ave & E 15 St', '2 Ave & E 31 St'], 9),\n",
       " (['1 Ave & E 15 St', '5 Ave & E 29 St'], 2),\n",
       " (['1 Ave & E 15 St', '6 Ave & Broome St'], 3),\n",
       " (['1 Ave & E 15 St', '6 Ave & Canal St'], 1),\n",
       " (['1 Ave & E 15 St', '8 Ave & W 31 St'], 5),\n",
       " (['1 Ave & E 15 St', '9 Ave & W 14 St'], 3),\n",
       " (['1 Ave & E 15 St', '9 Ave & W 16 St'], 3)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper3(_, row):\n",
    "    station= sorted([row['start_station_name'],\n",
    "                    row['end_station_name']])\n",
    "    yield(station,1)\n",
    "\n",
    "def reducer3(station_pair, counts):\n",
    "    yield(station_pair,sum(counts))\n",
    "    \n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output3 = list(mr.run(reader, mapper3, reducer3))\n",
    "\n",
    "output3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4\n",
    "\n",
    "In this task, you are asked to compute the station with the most riders started from, per each gender of the *'Subscriber'* user. Meaning, what was the station name with the highest number of bike pickups for female riders, for male riders and for unknown riders.\n",
    "\n",
    "The output will be a list of tuples, each includes a gender label (as indicated below) and another tuple consisting of a station name, and the total number of trips started at that station for that gender.\n",
    "\n",
    "The label mapping for the gender column in citibike.csv is: (Zero=<b>Unknown</b>; 1=<b>Male</b>; 2=<b>Female</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Unknown', [1, 'Catherine St & Monroe St']),\n",
       " ('Male', [488, '8 Ave & W 31 St']),\n",
       " ('Female', [107, 'W 21 St & 6 Ave'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper4(_,row):\n",
    "    if row['usertype']=='Subscriber':\n",
    "        yield((row['gender'],row[\"start_station_name\"]),1)\n",
    "        \n",
    "def reducer4(gender_station,counts):\n",
    "    yield(gender_station,sum(counts))\n",
    "    \n",
    "def mapper5(gender_station,count):\n",
    "    gender,station= gender_station\n",
    "    yield(gender,(station,count))\n",
    "          \n",
    "def reducer5(gender,station_counts):\n",
    "    max_station_count=max(station_counts,key=lambda x:x[1])\n",
    "    label =('Unknown','Male','Female')\n",
    "    yield(label[int(gender)],list(reversed(max_station_count)))\n",
    "          \n",
    "          \n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output5 = list(mr.run(mr.run(reader,mapper4,reducer4),mapper5,reducer5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 5\n",
    "\n",
    "We're going to tackle Task 3 of Homework 2 (or simply Homework 1) MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('P02291', (16, 1181.9700000000007)),\n",
       " ('P19498', (17, 989.9900000000007)),\n",
       " ('P32565', (17, 1006.0900000000007)),\n",
       " ('P33162', (18, 1210.9200000000008)),\n",
       " ('P39328', (17, 1129.0100000000007)),\n",
       " ('P58225', (17, 1349.8200000000008)),\n",
       " ('P61235', (18, 959.0200000000007)),\n",
       " ('P76615', (18, 1087.9600000000007)),\n",
       " ('P82222', (17, 950.0500000000006)),\n",
       " ('P92449', (14, 966.1700000000006))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#def mapper6(_,row):\n",
    " #   yield((row['Product ID'],(row['Customer ID'],float(row['Item ID']))))\n",
    "\n",
    "#def reducer6(pid,customer_costs):\n",
    "#    customers,costs=zip(*customer_costs)\n",
    " #   yield(pid,(len(set(customers)),sum(costs)))\n",
    "def mapper6(_,row):\n",
    "    yield(row['Product ID'],(row['Customer ID'],float(row['Item Cost'])))\n",
    "    \n",
    "def reducer6(pid,customer_costs):  \n",
    "    customers,costs = zip(*customer_costs)\n",
    "    yield(pid,(len(set(customers)),sum(costs)))\n",
    "    \n",
    "with open('sale.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output3 = list(mr.run(reader, mapper6,reducer6))\n",
    "\n",
    "output3[:10]\n",
    "           \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 6\n",
    "\n",
    "MRJob is a convenient packages for simplifying the execution of MapReduce jobs on clusters. However, it doesn't work in a notebook. We're going to convert some of the examples of MRJob into our notebooks so that we can test our code before deploying them on Hadoop.\n",
    "\n",
    "The two examples are available at:\n",
    "https://pythonhosted.org/mrjob/guides/quickstart.html\n",
    "https://pythonhosted.org/mrjob/guides/writing-mrjobs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 360),\n",
       " ('of', 326),\n",
       " ('and', 246),\n",
       " ('a', 169),\n",
       " ('or', 161),\n",
       " ('to', 101),\n",
       " ('with', 100),\n",
       " ('in', 88),\n",
       " ('on', 67),\n",
       " ('as', 56)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mrjob.job import MRJob\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRWordFreqCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield word.lower(), 1\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "        \n",
    "with open('book.txt', 'r',encoding='utf-8') as fi:\n",
    "    lines = [(i,line.strip()) for i,line in enumerate(fi) if i<1000]\n",
    "\n",
    "### After this, 'lines' stores a list of 1000 text lines\n",
    "def mapper(_, line):\n",
    "    for word in line.strip().split(' '):\n",
    "        if len(word)>0:\n",
    "            yield (word, 1)\n",
    "    \n",
    "def reducer(word, counts):\n",
    "    yield (word, sum(counts))\n",
    "    \n",
    "job=MRWordFreqCount()\n",
    "wCounts = list(mr.run(lines, mapper, reducer))\n",
    "sortedCounts = sorted(wCounts, key=lambda x: -x[1])\n",
    "sortedCounts[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
